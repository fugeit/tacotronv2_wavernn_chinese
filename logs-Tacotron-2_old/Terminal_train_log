
-----------------------------------------------------------------
Starting new Tacotron-2 training run
-----------------------------------------------------------------
[2020-06-18 11:38:36.680]  
#############################################################

[2020-06-18 11:38:36.680]  Tacotron Train

[2020-06-18 11:38:36.680]  ###########################################################

[2020-06-18 11:38:36.681]  Checkpoint path: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/logs-Tacotron-2/taco_pretrained/tacotron_model.ckpt
[2020-06-18 11:38:36.681]  Loading training data from: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset/bznsyp/training_data_v1/train.txt
[2020-06-18 11:38:36.681]  Using model: Tacotron-2
[2020-06-18 11:38:36.728]  Hyperparameters:
  GL_on_GPU: False
  allow_clipping_in_normalization: True
  attention_dim: 128
  attention_filters: 32
  attention_kernel: (31,)
  attention_win_size: 2
  base_dir: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset
  batch_norm_position: after
  cbhg_conv_channels: 128
  cbhg_highway_units: 128
  cbhg_highwaynet_layers: 4
  cbhg_kernels: 8
  cbhg_pool_size: 2
  cbhg_projection: 256
  cbhg_projection_kernel_size: 3
  cbhg_rnn_units: 128
  clip_for_wavenet: True
  clip_mels_length: False
  clip_outputs: True
  cross_entropy_pos_weight: 1
  cumulative_weights: True
  dataset: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset/bznsyp
  decoder_layers: 2
  decoder_lstm_units: 256
  embedding_dim: 128
  enc_conv_channels: 256
  enc_conv_kernel_size: (5,)
  enc_conv_num_layers: 3
  encoder_lstm_units: 256
  feat_out_dir: training_data_v1
  fmax: 7600
  fmin: 95
  frame_shift_ms: None
  griffin_lim_iters: 60
  hop_size: 275
  lower_bound_decay: 0.1
  magnitude_power: 2.0
  mask_decoder: False
  mask_encoder: True
  max_abs_value: 4.0
  max_iters: 40000
  max_mel_frames: 900
  min_level_db: -100
  n_fft: 2048
  normalize_for_wavenet: True
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 1
  postnet_channels: 256
  postnet_kernel_size: (5,)
  postnet_num_layers: 5
  power: 1.5
  predict_linear: False
  preemphasis: 0.97
  preemphasize: True
  prenet_layers: [256, 256]
  ref_level_db: 20
  rescale: True
  rescaling_max: 0.999
  sample_rate: 22050
  signal_normalization: True
  silence_threshold: 2
  smoothing: False
  split_on_cpu: True
  stop_at_any: True
  symmetric_mels: True
  synthesis_constraint: False
  synthesis_constraint_type: window
  tacotron_adam_beta1: 0.9
  tacotron_adam_beta2: 0.999
  tacotron_adam_epsilon: 1e-06
  tacotron_batch_size: 32
  tacotron_clip_gradients: True
  tacotron_data_random_state: 1234
  tacotron_decay_learning_rate: True
  tacotron_decay_rate: 0.5
  tacotron_decay_steps: 20000
  tacotron_dropout_rate: 0.5
  tacotron_final_learning_rate: 1e-05
  tacotron_fine_tuning: False
  tacotron_initial_learning_rate: 0.001
  tacotron_input: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset/bznsyp/training_data_v1/train.txt
  tacotron_natural_eval: True
  tacotron_num_gpus: 1
  tacotron_random_seed: 5339
  tacotron_reg_weight: 1e-06
  tacotron_scale_regularization: False
  tacotron_start_decay: 66000
  tacotron_swap_with_cpu: False
  tacotron_synthesis_batch_size: 1
  tacotron_teacher_forcing_decay_alpha: None
  tacotron_teacher_forcing_decay_steps: 150000
  tacotron_teacher_forcing_final_ratio: 0.3
  tacotron_teacher_forcing_init_ratio: 1.0
  tacotron_teacher_forcing_mode: constant
  tacotron_teacher_forcing_ratio: 1.0
  tacotron_teacher_forcing_start_decay: 70000
  tacotron_test_batches: None
  tacotron_test_size: 0.05
  tacotron_zoneout_rate: 0.1
  trim_fft_size: 2048
  trim_hop_size: 512
  trim_silence: True
  trim_top_db: 25
  use_all_outputs: False
  use_lws: False
  wavenet_num_gpus: 1
  wavenet_pad_sides: 1
  win_size: 1100
[2020-06-18 11:38:36.772]  Loaded metadata for 10000 examples (10.12 hours)
[2020-06-18 11:38:38.714]  initialisation done.
[2020-06-18 11:38:38.715]  Initialized Tacotron model. Dimensions (? = dynamic shape): 
[2020-06-18 11:38:38.715]    Train mode:               True
[2020-06-18 11:38:38.715]    Eval mode:                False
[2020-06-18 11:38:38.715]    GTA mode:                 False
[2020-06-18 11:38:38.715]    Synthesis mode:           False
[2020-06-18 11:38:38.715]    Input:                    (?, ?)
[2020-06-18 11:38:38.715]    embedding:                (?, ?, 128)
[2020-06-18 11:38:38.715]    enc conv out:             (?, ?, 256)
[2020-06-18 11:38:38.715]    encoder out:              (?, ?, 512)
[2020-06-18 11:38:38.715]    decoder out:              (?, ?, 80)
[2020-06-18 11:38:38.715]    residual out:             (?, ?, 256)
[2020-06-18 11:38:38.715]    projected residual out:   (?, ?, 80)
[2020-06-18 11:38:38.715]    mel out:                  (?, ?, 80)
[2020-06-18 11:38:38.715]    <stop_token> out:         (?, ?)
[2020-06-18 11:38:38.717]    Tacotron Parameters       5.162 Million.
[2020-06-18 11:38:38.718]   fine tune paarmaters:      3.266 Million.
[2020-06-18 11:38:38.719]   final  paarmaters:      5.162 Million.
[2020-06-18 11:38:45.051]  Tacotron training set to a maximum of 300000 steps
[2020-06-18 11:38:47.546]  Exiting due to exception: /home/spurs/tts/project/Tacotron-2_forward_attention_final/logs-Tacotron-2/taco_pretrained; No such file or directory

-----------------------------------------------------------------
Starting new Tacotron-2 training run
-----------------------------------------------------------------
[2020-06-18 12:11:16.268]  
#############################################################

[2020-06-18 12:11:16.268]  Tacotron Train

[2020-06-18 12:11:16.268]  ###########################################################

[2020-06-18 12:11:16.268]  Checkpoint path: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/logs-Tacotron-2/taco_pretrained/tacotron_model.ckpt
[2020-06-18 12:11:16.268]  Loading training data from: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset/bznsyp/training_data_v1/train.txt
[2020-06-18 12:11:16.268]  Using model: Tacotron-2
[2020-06-18 12:11:16.295]  Hyperparameters:
  GL_on_GPU: False
  allow_clipping_in_normalization: True
  attention_dim: 128
  attention_filters: 32
  attention_kernel: (31,)
  attention_win_size: 2
  base_dir: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset
  batch_norm_position: after
  cbhg_conv_channels: 128
  cbhg_highway_units: 128
  cbhg_highwaynet_layers: 4
  cbhg_kernels: 8
  cbhg_pool_size: 2
  cbhg_projection: 256
  cbhg_projection_kernel_size: 3
  cbhg_rnn_units: 128
  clip_for_wavenet: True
  clip_mels_length: False
  clip_outputs: True
  cross_entropy_pos_weight: 1
  cumulative_weights: True
  dataset: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset/bznsyp
  decoder_layers: 2
  decoder_lstm_units: 256
  embedding_dim: 128
  enc_conv_channels: 256
  enc_conv_kernel_size: (5,)
  enc_conv_num_layers: 3
  encoder_lstm_units: 256
  feat_out_dir: training_data_v1
  fmax: 7600
  fmin: 95
  frame_shift_ms: None
  griffin_lim_iters: 60
  hop_size: 275
  lower_bound_decay: 0.1
  magnitude_power: 2.0
  mask_decoder: False
  mask_encoder: True
  max_abs_value: 4.0
  max_iters: 40000
  max_mel_frames: 900
  min_level_db: -100
  n_fft: 2048
  normalize_for_wavenet: True
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 1
  postnet_channels: 256
  postnet_kernel_size: (5,)
  postnet_num_layers: 5
  power: 1.5
  predict_linear: False
  preemphasis: 0.97
  preemphasize: True
  prenet_layers: [256, 256]
  ref_level_db: 20
  rescale: True
  rescaling_max: 0.999
  sample_rate: 22050
  signal_normalization: True
  silence_threshold: 2
  smoothing: False
  split_on_cpu: True
  stop_at_any: True
  symmetric_mels: True
  synthesis_constraint: False
  synthesis_constraint_type: window
  tacotron_adam_beta1: 0.9
  tacotron_adam_beta2: 0.999
  tacotron_adam_epsilon: 1e-06
  tacotron_batch_size: 32
  tacotron_clip_gradients: True
  tacotron_data_random_state: 1234
  tacotron_decay_learning_rate: True
  tacotron_decay_rate: 0.5
  tacotron_decay_steps: 20000
  tacotron_dropout_rate: 0.5
  tacotron_final_learning_rate: 1e-05
  tacotron_fine_tuning: False
  tacotron_initial_learning_rate: 0.001
  tacotron_input: /Users/ccs/Desktop/myRepo/tacotronv2_wavernn_chinese/dataset/bznsyp/training_data_v1/train.txt
  tacotron_natural_eval: True
  tacotron_num_gpus: 1
  tacotron_random_seed: 5339
  tacotron_reg_weight: 1e-06
  tacotron_scale_regularization: False
  tacotron_start_decay: 66000
  tacotron_swap_with_cpu: False
  tacotron_synthesis_batch_size: 1
  tacotron_teacher_forcing_decay_alpha: None
  tacotron_teacher_forcing_decay_steps: 150000
  tacotron_teacher_forcing_final_ratio: 0.3
  tacotron_teacher_forcing_init_ratio: 1.0
  tacotron_teacher_forcing_mode: constant
  tacotron_teacher_forcing_ratio: 1.0
  tacotron_teacher_forcing_start_decay: 70000
  tacotron_test_batches: None
  tacotron_test_size: 0.05
  tacotron_zoneout_rate: 0.1
  trim_fft_size: 2048
  trim_hop_size: 512
  trim_silence: True
  trim_top_db: 25
  use_all_outputs: False
  use_lws: False
  wavenet_num_gpus: 1
  wavenet_pad_sides: 1
  win_size: 1100
[2020-06-18 12:11:16.335]  Loaded metadata for 10000 examples (10.12 hours)
[2020-06-18 12:11:18.180]  initialisation done.
[2020-06-18 12:11:18.181]  Initialized Tacotron model. Dimensions (? = dynamic shape): 
[2020-06-18 12:11:18.181]    Train mode:               True
[2020-06-18 12:11:18.181]    Eval mode:                False
[2020-06-18 12:11:18.181]    GTA mode:                 False
[2020-06-18 12:11:18.181]    Synthesis mode:           False
[2020-06-18 12:11:18.181]    Input:                    (?, ?)
[2020-06-18 12:11:18.181]    embedding:                (?, ?, 128)
[2020-06-18 12:11:18.181]    enc conv out:             (?, ?, 256)
[2020-06-18 12:11:18.181]    encoder out:              (?, ?, 512)
[2020-06-18 12:11:18.181]    decoder out:              (?, ?, 80)
[2020-06-18 12:11:18.181]    residual out:             (?, ?, 256)
[2020-06-18 12:11:18.181]    projected residual out:   (?, ?, 80)
[2020-06-18 12:11:18.181]    mel out:                  (?, ?, 80)
[2020-06-18 12:11:18.181]    <stop_token> out:         (?, ?)
[2020-06-18 12:11:18.183]    Tacotron Parameters       5.162 Million.
[2020-06-18 12:11:18.183]   fine tune paarmaters:      3.266 Million.
[2020-06-18 12:11:18.184]   final  paarmaters:      5.162 Million.
[2020-06-18 12:11:24.221]  Tacotron training set to a maximum of 300000 steps
[2020-06-18 12:11:26.805]  Exiting due to exception: /home/spurs/tts/project/Tacotron-2_forward_attention_final/logs-Tacotron-2/taco_pretrained; No such file or directory
